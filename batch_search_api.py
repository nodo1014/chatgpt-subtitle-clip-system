#!/usr/bin/env python3
"""
ë°°ì¹˜ ë‹¤ì¤‘ ë¬¸ì¥ ê²€ìƒ‰ API
270K+ ìë§‰ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì—¬ëŸ¬ ì˜ì–´ ë¬¸ì¥ì„ ë™ì‹œì— ê²€ìƒ‰í•˜ëŠ” Flask API

ê¸°ëŠ¥:
- í•œê¸€/íŠ¹ìˆ˜ë¬¸ì í•„í„°ë§
- ì˜ì–´ ë¬¸ì¥ ì¶”ì¶œ
- ë°°ì¹˜ ë°ì´í„°ë² ì´ìŠ¤ ê²€ìƒ‰
- ê²€ìƒ‰ íˆìŠ¤í† ë¦¬ ê´€ë¦¬
"""

import sqlite3
import re
import json
import time
from datetime import datetime
from flask import Flask, request, jsonify, render_template_string
from flask_cors import CORS
import unicodedata
import sys
import os

app = Flask(__name__)
CORS(app)

# í´ë¦½ ë§¤ë‹ˆì € ì„í¬íŠ¸
sys.path.append(os.path.join(os.path.dirname(__file__), 'indexer_v2'))
from clip_manager import ClipManager

# ë°ì´í„°ë² ì´ìŠ¤ ê²½ë¡œ ì„¤ì •
DB_PATHS = [
    '/home/kang/docker/youtube/indexer/indexer_v1/working_subtitles.db',
    '/home/kang/docker/youtube/indexer/indexer_v2/working_subtitles.db'
]

class BatchSearchEngine:
    def __init__(self):
        self.db_path = None
        self.connect_to_database()
        # í´ë¦½ ë§¤ë‹ˆì € ì´ˆê¸°í™”
        self.clip_manager = None
        try:
            from indexer_v2.clip_manager import ClipManager
            self.clip_manager = ClipManager(self.db_path)
        except ImportError:
            print("âš ï¸ í´ë¦½ ë§¤ë‹ˆì € ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í´ë¦¬í•‘ ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤.")
        except Exception as e:
            print(f"âš ï¸ í´ë¦½ ë§¤ë‹ˆì € ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    
    def connect_to_database(self):
        """ê°€ìš©í•œ ë°ì´í„°ë² ì´ìŠ¤ì— ì—°ê²°"""
        for db_path in DB_PATHS:
            try:
                conn = sqlite3.connect(db_path)
                cursor = conn.cursor()
                cursor.execute("SELECT COUNT(*) FROM subtitles LIMIT 1")
                count = cursor.fetchone()[0]
                conn.close()
                self.db_path = db_path
                print(f"âœ… ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„±ê³µ: {db_path} ({count:,}ê°œ ìë§‰)")
                return
            except Exception as e:
                print(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨: {db_path} - {e}")
                continue
        
        print("âš ï¸ ëª¨ë“  ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨ - ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œë¡œ ì‹¤í–‰")
    
    def extract_english_sentences(self, text):
        """í…ìŠ¤íŠ¸ì—ì„œ ì˜ì–´ ë¬¸ì¥ë§Œ ì¶”ì¶œ"""
        # í•œê¸€, í•œì, ì¼ë³¸ì–´ ë¬¸ì íŒ¨í„´
        asian_pattern = re.compile(r'[\u1100-\u11FF\u3130-\u318F\uAC00-\uD7AF\u4E00-\u9FFF\u3040-\u309F\u30A0-\u30FF]')
        
        # 1ë‹¨ê³„: ì¤„ë³„ë¡œ ë¶„ë¦¬í•˜ê³  ì•„ì‹œì•„ ë¬¸ìê°€ í¬í•¨ëœ ì¤„ ì œê±°
        lines = []
        for line in text.split('\n'):
            clean_line = line.strip()
            if clean_line and not asian_pattern.search(clean_line):
                lines.append(clean_line)
        
        # 2ë‹¨ê³„: ì˜ì–´ ë¬¸ì¥ ì¶”ì¶œ (ëŒ€ë¬¸ìë¡œ ì‹œì‘í•˜ê³  .?!ë¡œ ëë‚˜ëŠ” ë¬¸ì¥)
        sentences = []
        sentence_pattern = re.compile(r'[A-Z][^.!?]*[.!?]')
        
        for line in lines:
            matches = sentence_pattern.findall(line)
            for sentence in matches:
                trimmed = sentence.strip()
                # ìµœì†Œ ê¸¸ì´ì™€ ë‹¨ì–´ ìˆ˜ ì²´í¬
                if len(trimmed) >= 10 and len(trimmed.split()) >= 3:
                    # íŠ¹ìˆ˜ë¬¸ì ì •ë¦¬
                    clean_sentence = re.sub(r'[^\w\s\.\!\?]', '', trimmed)
                    if clean_sentence:
                        sentences.append(clean_sentence)
        
        return sentences
    
    def search_sentence_in_db(self, sentence, limit=10):
        """ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ë‹¨ì¼ ë¬¸ì¥ ê²€ìƒ‰"""
        if not self.db_path:
            return self.generate_mock_results(sentence, limit)
        
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # FTS5 ê²€ìƒ‰ (ì „ì²´ í…ìŠ¤íŠ¸ ê²€ìƒ‰)
            search_query = """
            SELECT 
                file_path,
                subtitle_text,
                start_time,
                end_time,
                duration,
                SUBSTR(file_path, INSTR(file_path, '/') + 1) as media_name
            FROM subtitles 
            WHERE subtitles MATCH ? 
            ORDER BY rank 
            LIMIT ?
            """
            
            cursor.execute(search_query, (sentence, limit))
            results = cursor.fetchall()
            conn.close()
            
            formatted_results = []
            for result in results:
                file_path, subtitle_text, start_time, end_time, duration, media_name = result
                
                # ì‹ ë¢°ë„ ê³„ì‚° (ë‹¨ìˆœí•œ ë¬¸ìì—´ ìœ ì‚¬ë„)
                confidence = self.calculate_confidence(sentence, subtitle_text)
                
                formatted_results.append({
                    'file_path': file_path,
                    'media_name': media_name,
                    'subtitle_text': subtitle_text,
                    'start_time': start_time,
                    'end_time': end_time,
                    'duration': duration,
                    'confidence': confidence,
                    'timestamp': f"{int(start_time//60):02d}:{int(start_time%60):02d}"
                })
            
            return formatted_results
            
        except Exception as e:
            print(f"ë°ì´í„°ë² ì´ìŠ¤ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return self.generate_mock_results(sentence, limit)
    
    def calculate_confidence(self, query, subtitle_text):
        """ê²€ìƒ‰ ê²°ê³¼ì˜ ì‹ ë¢°ë„ ê³„ì‚°"""
        query_words = set(query.lower().split())
        subtitle_words = set(subtitle_text.lower().split())
        
        if not query_words:
            return 0.0
        
        intersection = len(query_words.intersection(subtitle_words))
        confidence = intersection / len(query_words)
        return min(confidence, 1.0)
    
    def generate_mock_results(self, sentence, limit):
        """ì‹œë®¬ë ˆì´ì…˜ìš© ê°€ì§œ ê²°ê³¼ ìƒì„±"""
        mock_sources = [
            {"name": "Friends", "type": "TV Series"},
            {"name": "The Office", "type": "TV Series"},
            {"name": "Breaking Bad", "type": "TV Series"},
            {"name": "Stranger Things", "type": "TV Series"},
            {"name": "The Crown", "type": "TV Series"},
            {"name": "Sherlock", "type": "TV Series"},
            {"name": "House of Cards", "type": "TV Series"},
            {"name": "Black Mirror", "type": "TV Series"},
            {"name": "Westworld", "type": "TV Series"},
            {"name": "Game of Thrones", "type": "TV Series"}
        ]
        
        results = []
        for i in range(min(limit, len(mock_sources))):
            source = mock_sources[i]
            confidence = max(0.5, 1.0 - (i * 0.1))
            
            results.append({
                'file_path': f"/media/{source['name'].lower().replace(' ', '_')}/s01e01.srt",
                'media_name': source['name'],
                'subtitle_text': sentence,
                'start_time': 120 + i * 30,
                'end_time': 125 + i * 30,
                'duration': 5,
                'confidence': confidence,
                'timestamp': f"{int((120 + i * 30)//60):02d}:{int((120 + i * 30)%60):02d}"
            })
        
        return results
    
    def batch_search(self, sentences, results_per_sentence=10):
        """ë°°ì¹˜ ê²€ìƒ‰ ì‹¤í–‰"""
        search_start = time.time()
        all_results = []
        
        for i, sentence in enumerate(sentences):
            sentence_results = self.search_sentence_in_db(sentence, results_per_sentence)
            
            all_results.append({
                'sentence_index': i + 1,
                'search_sentence': sentence,
                'found_count': len(sentence_results),
                'results': sentence_results
            })
        
        search_end = time.time()
        
        return {
            'search_summary': {
                'total_sentences': len(sentences),
                'total_results': sum(r['found_count'] for r in all_results),
                'average_per_sentence': sum(r['found_count'] for r in all_results) / len(sentences) if sentences else 0,
                'search_time': round(search_end - search_start, 2)
            },
            'sentence_results': all_results,
            'timestamp': datetime.now().isoformat()
        }

# ì „ì—­ ê²€ìƒ‰ ì—”ì§„ ì¸ìŠ¤í„´ìŠ¤
search_engine = BatchSearchEngine()

@app.route('/')
def index():
    """ë©”ì¸ í˜ì´ì§€"""
    return """
    <!DOCTYPE html>
    <html>
    <head>
        <title>ë°°ì¹˜ ê²€ìƒ‰ API</title>
        <style>
            body { font-family: Arial, sans-serif; margin: 40px; }
            .container { max-width: 800px; margin: 0 auto; }
            .endpoint { background: #f5f5f5; padding: 15px; margin: 10px 0; border-radius: 5px; }
            .method { background: #007bff; color: white; padding: 3px 8px; border-radius: 3px; font-size: 12px; }
        </style>
    </head>
    <body>
        <div class="container">
            <h1>ğŸ” ë°°ì¹˜ ë‹¤ì¤‘ ë¬¸ì¥ ê²€ìƒ‰ API</h1>
            <p>270K+ ìë§‰ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì—¬ëŸ¬ ì˜ì–´ ë¬¸ì¥ì„ ë™ì‹œì— ê²€ìƒ‰í•©ë‹ˆë‹¤.</p>
            
            <h2>API ì—”ë“œí¬ì¸íŠ¸</h2>
            
            <div class="endpoint">
                <h3><span class="method">POST</span> /api/batch-search</h3>
                <p><strong>ì„¤ëª…:</strong> ë°°ì¹˜ ë‹¤ì¤‘ ë¬¸ì¥ ê²€ìƒ‰</p>
                <p><strong>íŒŒë¼ë¯¸í„°:</strong></p>
                <ul>
                    <li><code>text</code> - ê²€ìƒ‰í•  í…ìŠ¤íŠ¸ (í•œê¸€/ì˜ì–´ í˜¼í•© ê°€ëŠ¥)</li>
                    <li><code>results_per_sentence</code> - ë¬¸ì¥ë‹¹ ê²°ê³¼ ìˆ˜ (ê¸°ë³¸ê°’: 10)</li>
                </ul>
            </div>
            
            <div class="endpoint">
                <h3><span class="method">POST</span> /api/extract-sentences</h3>
                <p><strong>ì„¤ëª…:</strong> í…ìŠ¤íŠ¸ì—ì„œ ì˜ì–´ ë¬¸ì¥ë§Œ ì¶”ì¶œ</p>
                <p><strong>íŒŒë¼ë¯¸í„°:</strong></p>
                <ul>
                    <li><code>text</code> - ì¶”ì¶œí•  í…ìŠ¤íŠ¸</li>
                </ul>
            </div>
            
            <div class="endpoint">
                <h3><span class="method">GET</span> /api/status</h3>
                <p><strong>ì„¤ëª…:</strong> API ìƒíƒœ ë° ë°ì´í„°ë² ì´ìŠ¤ ì •ë³´</p>
            </div>
            
            <h2>ì‚¬ìš© ì˜ˆì‹œ</h2>
            <pre style="background: #f8f9fa; padding: 15px; border-radius: 5px;">
curl -X POST http://localhost:5000/api/batch-search \\
  -H "Content-Type: application/json" \\
  -d '{
    "text": "The meeting has been postponed until next Wednesday.\\níšŒì˜ê°€ ë‹¤ìŒ ì£¼ ìˆ˜ìš”ì¼ë¡œ ì—°ê¸°ë˜ì—ˆìŠµë‹ˆë‹¤.\\nPlease submit your reports by the end of the month.",
    "results_per_sentence": 10
  }'
            </pre>
        </div>
    </body>
    </html>
    """

@app.route('/api/status', methods=['GET'])
def api_status():
    """API ìƒíƒœ ì •ë³´"""
    status = {
        'status': 'active',
        'database_connected': search_engine.db_path is not None,
        'database_path': search_engine.db_path,
        'timestamp': datetime.now().isoformat()
    }
    
    if search_engine.db_path:
        try:
            conn = sqlite3.connect(search_engine.db_path)
            cursor = conn.cursor()
            cursor.execute("SELECT COUNT(*) FROM subtitles")
            count = cursor.fetchone()[0]
            conn.close()
            status['subtitle_count'] = count
        except:
            status['subtitle_count'] = 'unknown'
    
    return jsonify(status)

@app.route('/api/extract-sentences', methods=['POST'])
def extract_sentences():
    """í…ìŠ¤íŠ¸ì—ì„œ ì˜ì–´ ë¬¸ì¥ ì¶”ì¶œ"""
    data = request.get_json()
    
    if not data or 'text' not in data:
        return jsonify({'error': 'í…ìŠ¤íŠ¸ê°€ í•„ìš”í•©ë‹ˆë‹¤'}), 400
    
    text = data['text']
    sentences = search_engine.extract_english_sentences(text)
    
    return jsonify({
        'original_text': text,
        'extracted_sentences': sentences,
        'sentence_count': len(sentences),
        'timestamp': datetime.now().isoformat()
    })

@app.route('/api/batch-search', methods=['POST'])
def batch_search():
    """ë°°ì¹˜ ë‹¤ì¤‘ ë¬¸ì¥ ê²€ìƒ‰"""
    data = request.get_json()
    
    if not data or 'text' not in data:
        return jsonify({'error': 'í…ìŠ¤íŠ¸ê°€ í•„ìš”í•©ë‹ˆë‹¤'}), 400
    
    text = data['text']
    results_per_sentence = data.get('results_per_sentence', 10)
    
    # ì˜ì–´ ë¬¸ì¥ ì¶”ì¶œ
    sentences = search_engine.extract_english_sentences(text)
    
    if not sentences:
        return jsonify({
            'error': 'ì˜ì–´ ë¬¸ì¥ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤',
            'original_text': text,
            'extracted_sentences': [],
            'suggestion': 'ëŒ€ë¬¸ìë¡œ ì‹œì‘í•˜ê³  ë§ˆì¹¨í‘œë¡œ ëë‚˜ëŠ” ì˜ì–´ ë¬¸ì¥ì„ ì…ë ¥í•´ì£¼ì„¸ìš”'
        }), 400
    
    # ë°°ì¹˜ ê²€ìƒ‰ ì‹¤í–‰
    results = search_engine.batch_search(sentences, results_per_sentence)
    
    return jsonify({
        'success': True,
        'original_text': text,
        'extracted_sentences': sentences,
        **results
    })

@app.route('/api/search-history', methods=['GET'])
def get_search_history():
    """ê²€ìƒ‰ íˆìŠ¤í† ë¦¬ ì¡°íšŒ (ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ë°ì´í„°ë² ì´ìŠ¤ ì‚¬ìš©)"""
    # ì„ì‹œë¡œ íŒŒì¼ ê¸°ë°˜ íˆìŠ¤í† ë¦¬ (ì‹¤ì œë¡œëŠ” ë°ì´í„°ë² ì´ìŠ¤ ì‚¬ìš©)
    try:
        with open('/tmp/batch_search_history.json', 'r', encoding='utf-8') as f:
            history = json.load(f)
    except:
        history = []
    
    return jsonify(history[-10:])  # ìµœê·¼ 10ê°œ

@app.route('/api/save-search', methods=['POST'])
def save_search():
    """ê²€ìƒ‰ ê²°ê³¼ ì €ì¥"""
    data = request.get_json()
    
    if not data:
        return jsonify({'error': 'ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤'}), 400
    
    # ê²€ìƒ‰ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
    history_item = {
        'timestamp': datetime.now().isoformat(),
        'sentences': data.get('sentences', []),
        'total_results': data.get('total_results', 0),
        'search_type': 'batch'
    }
    
    try:
        # ê¸°ì¡´ íˆìŠ¤í† ë¦¬ ì½ê¸°
        try:
            with open('/tmp/batch_search_history.json', 'r', encoding='utf-8') as f:
                history = json.load(f)
        except:
            history = []
        
        # ìƒˆ í•­ëª© ì¶”ê°€
        history.append(history_item)
        history = history[-50:]  # ìµœëŒ€ 50ê°œë§Œ ìœ ì§€
        
        # íŒŒì¼ì— ì €ì¥
        with open('/tmp/batch_search_history.json', 'w', encoding='utf-8') as f:
            json.dump(history, f, ensure_ascii=False, indent=2)
        
        return jsonify({'success': True, 'message': 'ê²€ìƒ‰ íˆìŠ¤í† ë¦¬ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤'})
    
    except Exception as e:
        return jsonify({'error': f'ì €ì¥ ì‹¤íŒ¨: {str(e)}'}), 500

# í´ë¦¬í•‘ ê´€ë ¨ API ì—”ë“œí¬ì¸íŠ¸
@app.route('/api/request-clip', methods=['POST'])
def request_clip():
    """í´ë¦½ ì¦‰ì‹œ ìƒì„± (ìë™ ì²˜ë¦¬)"""
    try:
        data = request.json
        sentence = data.get('sentence', '')
        media_file = data.get('media_file', '')
        start_time = data.get('start_time', '')
        end_time = data.get('end_time', '')
        
        if not all([sentence, media_file, start_time, end_time]):
            return jsonify({'error': 'í•„ìˆ˜ í•„ë“œê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤'}), 400
        
        # í´ë¦½ ë§¤ë‹ˆì € ì„í¬íŠ¸ ë° ì‚¬ìš©
        import sys
        import os
        sys.path.append(os.path.join(os.path.dirname(__file__), 'indexer_v2'))
        from clip_manager import ClipManager
        
        clip_manager = ClipManager(search_engine.db_path)
        
        # 1ë‹¨ê³„: í´ë¦½ ìš”ì²­ ë“±ë¡
        request_result = clip_manager.request_single_clip(
            sentence=sentence,
            media_file=media_file,
            start_time=start_time,
            end_time=end_time
        )
        
        if not request_result['success']:
            return jsonify(request_result)
        
        clip_id = request_result['clip_id']
        
        # 2ë‹¨ê³„: ì¦‰ì‹œ í´ë¦½ ìƒì„± ì‹œë„
        try:
            creation_result = clip_manager.manual_clip_creation(clip_id)
            
            if creation_result['success']:
                return jsonify({
                    'success': True,
                    'clip_id': clip_id,
                    'message': 'í´ë¦½ì´ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!',
                    'output_path': creation_result.get('output_path', ''),
                    'type': 'immediate'
                })
            else:
                # í´ë¦½ ìƒì„± ì‹¤íŒ¨ì‹œ ìš”ì²­ë§Œ ë“±ë¡ëœ ìƒíƒœë¡œ ë°˜í™˜
                return jsonify({
                    'success': True,
                    'clip_id': clip_id,
                    'message': f'í´ë¦½ ìš”ì²­ì´ ë“±ë¡ë˜ì—ˆìŠµë‹ˆë‹¤. ìƒì„± ì˜¤ë¥˜: {creation_result.get("error", "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜")}',
                    'warning': creation_result.get('error', ''),
                    'type': 'queued'
                })
                
        except Exception as creation_error:
            # í´ë¦½ ìƒì„± ì¤‘ ì˜ˆì™¸ ë°œìƒì‹œì—ë„ ìš”ì²­ì€ ë“±ë¡ëœ ìƒíƒœ
            return jsonify({
                'success': True,
                'clip_id': clip_id,
                'message': f'í´ë¦½ ìš”ì²­ì´ ë“±ë¡ë˜ì—ˆìŠµë‹ˆë‹¤. ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(creation_error)}',
                'warning': str(creation_error),
                'type': 'queued'
            })
        
        return jsonify(request_result)
    
    except Exception as e:
        return jsonify({'error': f'í´ë¦½ ìš”ì²­ ì‹¤íŒ¨: {str(e)}'}), 500

@app.route('/api/pending-clips', methods=['GET'])
def get_pending_clips():
    """ëŒ€ê¸° ì¤‘ì¸ í´ë¦½ ìš”ì²­ ëª©ë¡"""
    try:
        import sys
        import os
        sys.path.append(os.path.join(os.path.dirname(__file__), 'indexer_v2'))
        from clip_manager import ClipManager
        
        clip_manager = ClipManager(search_engine.db_path)
        clips = clip_manager.get_pending_clips()
        
        return jsonify({
            'success': True,
            'clips': clips,
            'count': len(clips)
        })
    
    except Exception as e:
        return jsonify({'error': f'í´ë¦½ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}'}), 500

@app.route('/api/create-clip', methods=['POST'])
def create_clip():
    """í´ë¦½ ìƒì„± (ìˆ˜ë™ ì²˜ë¦¬ìš© - CLIì—ì„œ í˜¸ì¶œ)"""
    try:
        data = request.json
        clip_id = data.get('clip_id', '')
        
        if not clip_id:
            return jsonify({'error': 'clip_idê°€ í•„ìš”í•©ë‹ˆë‹¤'}), 400
        
        import sys
        import os
        sys.path.append(os.path.join(os.path.dirname(__file__), 'indexer_v2'))
        from clip_manager import ClipManager
        
        clip_manager = ClipManager(search_engine.db_path)
        result = clip_manager.manual_clip_creation(clip_id)
        
        return jsonify(result)
    
    except Exception as e:
        return jsonify({'error': f'í´ë¦½ ìƒì„± ì‹¤íŒ¨: {str(e)}'}), 500

if __name__ == '__main__':
    print("ğŸš€ ë°°ì¹˜ ê²€ìƒ‰ API ì„œë²„ ì‹œì‘")
    print("ğŸ“Š ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í™•ì¸ ì¤‘...")
    
    # ë°ì´í„°ë² ì´ìŠ¤ ìƒíƒœ ì¶œë ¥
    if search_engine.db_path:
        try:
            conn = sqlite3.connect(search_engine.db_path)
            cursor = conn.cursor()
            cursor.execute("SELECT COUNT(*) FROM subtitles")
            count = cursor.fetchone()[0]
            conn.close()
            print(f"âœ… ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„±ê³µ: {count:,}ê°œ ìë§‰ ë°ì´í„°")
        except Exception as e:
            print(f"âš ï¸ ë°ì´í„°ë² ì´ìŠ¤ ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {e}")
    else:
        print("âš ï¸ ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œë¡œ ì‹¤í–‰")
    
    print("ğŸŒ ì„œë²„ ì£¼ì†Œ: http://localhost:5000")
    print("ğŸ“– API ë¬¸ì„œ: http://localhost:5000")
    
    app.run(debug=True, host='0.0.0.0', port=5000)
